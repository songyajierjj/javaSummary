http://blog.csdn.net/shymi1991/article/details/52971994

http://blog.csdn.net/tangdong3415/article/details/53432166
1启动kafka(启动之前先启动zookeeper)
sh bin/kafka-server-start.sh config/server.properties

2创建一个test的topic
topic 名字为test，2个副本和1个分块
sh bin/kafka-topics.sh --create --zookeeper 192.168.40.46:2181 --replication-factor 2 --partitions 1 --topic test
提示：Created topic "test".

可以通过list命令查看创建的topic:
sh bin/kafka-topics.sh --list --zookeeper 192.168.40.46:2181
显示：test

3运行producer并在控制台中输一些消息，这些消息将被发送到服务端：
sh bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 

4Kafka也有一个命令行consumer可以读取消息并输出到标准输出：
sh bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning


describe topics命令来观察哪一个代理在处理该topic。
sh bin/kafka-topics.sh --describe --zookeeper 192.168.40.46:2181 --topic my-replicated-topic

第一行是topic概观，描述该topic的信息。接下来每一行显示该topic一个分块的信息。因为我们这个topic只有一个分块，所以只有一行。
Leader：负责该分块的读写，随机选举出来的节点；
replica：复制分块的节点；
isr：是replica的子集，leader的候选集，即slave。

在该例子中，node 1是mytest2唯一一个分块的leader。

Topic:mytest2   PartitionCount:1        ReplicationFactor:2     Configs:
Topic: mytest2  Partition: 0    Leader: 1       Replicas: 1,2   Isr: 1,2


容错测试。我们kill作为leader的Broker 1：
ps aux | grep server2.properties


Producer：Producer即生产者，消息的产生者，是消息的入口。
kafka cluster：
Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号
Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic
Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！
Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。
在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。
Message：每一条发送的消息主体。
Consumer：消费者，即消息的消费方，是消息的出口。
Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。
同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！
Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。
消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的！


Kafka速度的秘诀在于，它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗，
通过mmap提高I/O速度，
写入数据的时候由于单个partition是末尾添加所以速度最优；
读取数据的时候配合sendfile直接暴力输出。

顺序读写，压缩，零拷贝，多个partition,每个partition有多个segment，增加并行操作能力

异步发送，发送时先缓存到达一定数量再批量发送，提高io，降低性能
消息批量压缩
读取mmap提高i/o速度
顺序写入 （不能删除消息）
读取配置sendfile，零拷贝

